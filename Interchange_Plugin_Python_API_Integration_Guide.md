# Unreal Engine 5.5 Interchangeæ’ä»¶Python APIé›†æˆæŒ‡å—

## 1. å¯è¡Œæ€§åˆ†æ

### 1.1 ç°æœ‰Python APIæ”¯æŒ
Unreal Engine 5.5å·²ç»ä¸ºInterchangeç³»ç»Ÿæä¾›äº†åŸºç¡€çš„Python APIæ”¯æŒï¼Œä¸»è¦åŒ…æ‹¬ï¼š

```python
import unreal

# æ ¸å¿ƒInterchangeç±»
interchange_manager = unreal.InterchangeManager.get_interchange_manager_scripted()
source_data = unreal.InterchangeManager.create_source_data(file_path)
```

è¿™äº›APIå…è®¸åŸºæœ¬çš„èµ„äº§å¯¼å…¥æ“ä½œï¼Œä½†ç›®å‰**ä¸åŒ…å«å¯¹è‡ªå®šä¹‰ç¿»è¯‘å™¨ã€èŠ‚ç‚¹å’Œç®¡é“çš„å®Œæ•´è®¿é—®**ã€‚

### 1.2 è‡ªå®šä¹‰æ’ä»¶APIæš´éœ²å¯è¡Œæ€§

åŸºäºå¯¹ç°æœ‰ä»£ç çš„åˆ†æï¼Œå°†è‡ªå®šä¹‰Interchangeæ’ä»¶APIæš´éœ²ç»™Pythonæ˜¯å®Œå…¨å¯è¡Œçš„ï¼Œä¸»è¦é€šè¿‡ä»¥ä¸‹æœºåˆ¶ï¼š

1. **UCLASSå®æ ‡è®°**: æ‰€æœ‰å…³é”®ç±»å·²ä½¿ç”¨`UCLASS(BlueprintType)`æ ‡è®°ï¼Œè¿™æ˜¯Pythonç»‘å®šçš„åŸºç¡€
2. **UFUNCTIONå®**: å¯ä»¥ä¸ºå…³é”®æ–¹æ³•æ·»åŠ `UFUNCTION(BlueprintCallable)`ä½¿å…¶åœ¨Pythonä¸­å¯ç”¨
3. **UPROPERTYå®**: å¯ä»¥ä¸ºå±æ€§æ·»åŠ `UPROPERTY(BlueprintReadWrite)`ä½¿å…¶åœ¨Pythonä¸­å¯è®¿é—®

## 2. æ ¸å¿ƒAPIæš´éœ²æ–¹æ¡ˆ

### 2.1 ç¿»è¯‘å™¨APIæš´éœ²

```cpp
// ä¿®æ”¹å‰
UCLASS(BlueprintType)
class CUSTOMIMPORT_API UCustomFooTranslator : public UInterchangeTranslatorBase, 
                                             public ICustomDemoObjectPayloadInterface
{
    GENERATED_BODY()
public:
    virtual TArray<FString> GetSupportedFormats() const override;
    virtual bool Translate(UInterchangeBaseNodeContainer& BaseNodeContainer) const override;
    virtual TOptional<UE::Interchange::FCustomDemoObjectData> GetDemoObjectPayloadData(const FString& PayloadKey) const override;
};

// ä¿®æ”¹å - æ·»åŠ Pythonæ”¯æŒ
UCLASS(BlueprintType)
class CUSTOMIMPORT_API UCustomFooTranslator : public UInterchangeTranslatorBase, 
                                             public ICustomDemoObjectPayloadInterface
{
    GENERATED_BODY()
public:
    // æš´éœ²ç»™Pythonçš„æ ¼å¼è·å–æ–¹æ³•
    UFUNCTION(BlueprintCallable, Category = "Interchange|Translator|Custom")
    virtual TArray<FString> GetSupportedFormats() const override;
    
    // ç¿»è¯‘æ–¹æ³• - éœ€è¦åŒ…è£…ä»¥ä¾¿Pythonè°ƒç”¨
    virtual bool Translate(UInterchangeBaseNodeContainer& BaseNodeContainer) const override;
    
    // Pythonå‹å¥½çš„ç¿»è¯‘æ–¹æ³•åŒ…è£…
    UFUNCTION(BlueprintCallable, Category = "Interchange|Translator|Custom")
    bool TranslateFromPath(const FString& FilePath, const FString& DestinationPath);
    
    // è½½è·æ•°æ®æ¥å£ - éœ€è¦åŒ…è£…
    virtual TOptional<UE::Interchange::FCustomDemoObjectData> GetDemoObjectPayloadData(const FString& PayloadKey) const override;
    
    // Pythonå‹å¥½çš„è½½è·æ•°æ®è·å–
    UFUNCTION(BlueprintCallable, Category = "Interchange|Translator|Custom")
    FString GetPayloadDataAsJson(const FString& PayloadKey) const;
};
```

### 2.2 èŠ‚ç‚¹APIæš´éœ²

```cpp
// ä¿®æ”¹å‰
UCLASS(BlueprintType)
class CUSTOMNODES_API UCustomDemoObjectNode : public UInterchangeBaseNode
{
    GENERATED_BODY()
    
public:
    void InitializeCustomDemoObjectNode(const FString& UniqueID, const FString& DisplayLabel);
    virtual FString GetTypeName() const override { return TEXT("CustomDemoObjectNode"); }
    virtual const TOptional<FString> GetPayLoadKey() const;
    virtual void SetPayLoadKey(const FString& PayLoadKey);
};

// ä¿®æ”¹å - æ·»åŠ Pythonæ”¯æŒ
UCLASS(BlueprintType)
class CUSTOMNODES_API UCustomDemoObjectNode : public UInterchangeBaseNode
{
    GENERATED_BODY()
    
public:
    // åˆå§‹åŒ–æ–¹æ³• - å·²ç»æ˜¯UFUNCTION
    UFUNCTION(BlueprintCallable, Category = "Interchange|Node|Custom")
    void InitializeCustomDemoObjectNode(const FString& UniqueID, const FString& DisplayLabel);
    
    // ç±»å‹åç§° - æ·»åŠ Pythonè®¿é—®
    UFUNCTION(BlueprintCallable, Category = "Interchange|Node|Custom")
    virtual FString GetTypeName() const override { return TEXT("CustomDemoObjectNode"); }
    
    // è½½è·é”®è·å– - éœ€è¦åŒ…è£…
    virtual const TOptional<FString> GetPayLoadKey() const;
    
    // Pythonå‹å¥½çš„è½½è·é”®è·å–
    UFUNCTION(BlueprintCallable, Category = "Interchange|Node|Custom")
    FString GetPayLoadKeyForPython() const;
    
    // è½½è·é”®è®¾ç½® - å·²ç»æ˜¯UFUNCTION
    UFUNCTION(BlueprintCallable, Category = "Interchange|Node|Custom")
    virtual void SetPayLoadKey(const FString& PayLoadKey);
    
    // æ·»åŠ Pythonå‹å¥½çš„å±æ€§è®¿é—®æ–¹æ³•
    UFUNCTION(BlueprintCallable, Category = "Interchange|Node|Custom")
    bool SetCustomAttribute(const FString& AttributeName, const FString& AttributeValue);
    
    UFUNCTION(BlueprintCallable, Category = "Interchange|Node|Custom")
    bool GetCustomAttribute(const FString& AttributeName, FString& OutAttributeValue) const;
};
```

### 2.3 ç®¡é“APIæš´éœ²

```cpp
// ä¿®æ”¹å‰
UCLASS(BlueprintType, editinlinenew)
class CUSTOMPIPELINES_API UCustomDemoObjectPipeline : public UInterchangePipelineBase
{
    GENERATED_BODY()
    
public:
    UPROPERTY(EditAnywhere, BlueprintReadWrite, Category = "DemoObjects")
    bool bImportDemoObjects = true;
    
    UPROPERTY(EditAnywhere, BlueprintReadWrite, Category = "DemoObjects")
    bool bAssetSettingBoolean = false;
    
    UPROPERTY(EditAnywhere, BlueprintReadWrite, Category = "DemoObjects")
    float AssetSettingFloat = 0.0f;
    
    virtual void ExecutePipeline(UInterchangeBaseNodeContainer* InBaseNodeContainer, 
                                const TArray<UInterchangeSourceData*>& InSourceDatas, 
                                const FString& ContentBasePath) override;
};

// ä¿®æ”¹å - æ·»åŠ Pythonæ”¯æŒ
UCLASS(BlueprintType, editinlinenew)
class CUSTOMPIPELINES_API UCustomDemoObjectPipeline : public UInterchangePipelineBase
{
    GENERATED_BODY()
    
public:
    // é…ç½®å±æ€§ - å·²ç»å¯ä»¥ä»Pythonè®¿é—®
    UPROPERTY(EditAnywhere, BlueprintReadWrite, Category = "DemoObjects")
    bool bImportDemoObjects = true;
    
    UPROPERTY(EditAnywhere, BlueprintReadWrite, Category = "DemoObjects")
    bool bAssetSettingBoolean = false;
    
    UPROPERTY(EditAnywhere, BlueprintReadWrite, Category = "DemoObjects")
    float AssetSettingFloat = 0.0f;
    
    // æ‰§è¡Œç®¡é“ - éœ€è¦åŒ…è£…
    virtual void ExecutePipeline(UInterchangeBaseNodeContainer* InBaseNodeContainer, 
                                const TArray<UInterchangeSourceData*>& InSourceDatas, 
                                const FString& ContentBasePath) override;
    
    // Pythonå‹å¥½çš„ç®¡é“æ‰§è¡Œ
    UFUNCTION(BlueprintCallable, Category = "Interchange|Pipeline|Custom")
    bool ExecutePipelineFromPython(const TArray<FString>& FilePaths, const FString& DestinationPath);
    
    // æ·»åŠ Pythoné…ç½®æ–¹æ³•
    UFUNCTION(BlueprintCallable, Category = "Interchange|Pipeline|Custom")
    void ConfigurePipelineFromPython(const TMap<FString, FString>& ConfigOptions);
};
```

### 2.4 å·¥å‚APIæš´éœ²

```cpp
// ä¿®æ”¹å‰
UCLASS(BlueprintType)
class CUSTOMIMPORT_API UCustomDemoObjectFactory : public UInterchangeFactoryBase
{
    GENERATED_BODY()
    
public:
    virtual UClass* GetFactoryClass() const override;
    virtual EInterchangeFactoryAssetType GetFactoryAssetType() override;
    virtual FImportAssetResult BeginImportAsset_GameThread(const FImportAssetObjectParams& Arguments) override;
    virtual FImportAssetResult ImportAsset_Async(const FImportAssetObjectParams& Arguments) override;
    virtual void SetupObject_GameThread(const FSetupObjectParams& Arguments) override;
};

// ä¿®æ”¹å - æ·»åŠ Pythonæ”¯æŒ
UCLASS(BlueprintType)
class CUSTOMIMPORT_API UCustomDemoObjectFactory : public UInterchangeFactoryBase
{
    GENERATED_BODY()
    
public:
    // å·¥å‚ç±»è·å– - æ·»åŠ Pythonè®¿é—®
    UFUNCTION(BlueprintCallable, Category = "Interchange|Factory|Custom")
    virtual UClass* GetFactoryClass() const override;
    
    // èµ„äº§ç±»å‹è·å– - æ·»åŠ Pythonè®¿é—®
    UFUNCTION(BlueprintCallable, Category = "Interchange|Factory|Custom")
    virtual EInterchangeFactoryAssetType GetFactoryAssetType() override;
    
    // å¯¼å…¥æ–¹æ³• - å†…éƒ¨å®ç°
    virtual FImportAssetResult BeginImportAsset_GameThread(const FImportAssetObjectParams& Arguments) override;
    virtual FImportAssetResult ImportAsset_Async(const FImportAssetObjectParams& Arguments) override;
    virtual void SetupObject_GameThread(const FSetupObjectParams& Arguments) override;
    
    // Pythonå‹å¥½çš„å·¥å‚æ–¹æ³•
    UFUNCTION(BlueprintCallable, Category = "Interchange|Factory|Custom")
    UObject* CreateAssetFromPython(const FString& AssetPath, const FString& AssetName);
    
    // è‡ªå®šä¹‰è®¾ç½®æ–¹æ³•
    UFUNCTION(BlueprintCallable, Category = "Interchange|Factory|Custom")
    void ConfigureFactoryFromPython(const TMap<FString, FString>& FactorySettings);
};
```

## 3. PythonåŒ…è£…å±‚å®ç°

### 3.1 Pythonæ¨¡å—ç»“æ„

```python
# custom_interchange/__init__.py
from .translators import CustomFooTranslator
from .nodes import CustomDemoObjectNode
from .pipelines import CustomDemoObjectPipeline
from .factories import CustomDemoObjectFactory

# ç‰ˆæœ¬ä¿¡æ¯
__version__ = "1.0.0"
```

### 3.2 ç¿»è¯‘å™¨åŒ…è£…ç¤ºä¾‹

```python
# custom_interchange/translators.py
import unreal

class CustomFooTranslator:
    """PythonåŒ…è£…ç±»ï¼Œç”¨äºè®¿é—®UCustomFooTranslator"""
    
    @staticmethod
    def create():
        """åˆ›å»ºç¿»è¯‘å™¨å®ä¾‹"""
        return unreal.CustomFooTranslator()
    
    @staticmethod
    def get_supported_formats():
        """è·å–æ”¯æŒçš„æ ¼å¼åˆ—è¡¨"""
        translator = unreal.CustomFooTranslator()
        return translator.get_supported_formats()
    
    @staticmethod
    def translate_file(file_path, destination_path):
        """ç¿»è¯‘æ–‡ä»¶å¹¶å¯¼å…¥åˆ°æŒ‡å®šè·¯å¾„"""
        translator = unreal.CustomFooTranslator()
        return translator.translate_from_path(file_path, destination_path)
    
    @staticmethod
    def get_payload_data(payload_key):
        """è·å–è½½è·æ•°æ®"""
        translator = unreal.CustomFooTranslator()
        json_data = translator.get_payload_data_as_json(payload_key)
        # å¯ä»¥è¿›ä¸€æ­¥è§£æJSON
        import json
        return json.loads(json_data)
```

### 3.3 èŠ‚ç‚¹åŒ…è£…ç¤ºä¾‹

```python
# custom_interchange/nodes.py
import unreal

class CustomDemoObjectNode:
    """PythonåŒ…è£…ç±»ï¼Œç”¨äºè®¿é—®UCustomDemoObjectNode"""
    
    def __init__(self, node_instance=None):
        """åˆå§‹åŒ–èŠ‚ç‚¹åŒ…è£…å™¨"""
        self._node = node_instance if node_instance else None
    
    @staticmethod
    def create(unique_id, display_label):
        """åˆ›å»ºæ–°èŠ‚ç‚¹"""
        # éœ€è¦é€šè¿‡å®¹å™¨åˆ›å»ºèŠ‚ç‚¹
        container = unreal.InterchangeBaseNodeContainer()
        node = unreal.CustomDemoObjectNode()
        node.initialize_custom_demo_object_node(unique_id, display_label)
        wrapper = CustomDemoObjectNode(node)
        return wrapper
    
    def get_type_name(self):
        """è·å–èŠ‚ç‚¹ç±»å‹åç§°"""
        return self._node.get_type_name()
    
    def get_payload_key(self):
        """è·å–è½½è·é”®"""
        return self._node.get_pay_load_key_for_python()
    
    def set_payload_key(self, payload_key):
        """è®¾ç½®è½½è·é”®"""
        self._node.set_pay_load_key(payload_key)
    
    def set_attribute(self, name, value):
        """è®¾ç½®è‡ªå®šä¹‰å±æ€§"""
        return self._node.set_custom_attribute(name, str(value))
    
    def get_attribute(self, name):
        """è·å–è‡ªå®šä¹‰å±æ€§"""
        value = ""
        success = self._node.get_custom_attribute(name, value)
        return value if success else None
```

### 3.4 ç®¡é“åŒ…è£…ç¤ºä¾‹

```python
# custom_interchange/pipelines.py
import unreal

class CustomDemoObjectPipeline:
    """PythonåŒ…è£…ç±»ï¼Œç”¨äºè®¿é—®UCustomDemoObjectPipeline"""
    
    @staticmethod
    def create():
        """åˆ›å»ºç®¡é“å®ä¾‹"""
        return unreal.CustomDemoObjectPipeline()
    
    @staticmethod
    def execute(file_paths, destination_path):
        """æ‰§è¡Œç®¡é“å¤„ç†"""
        pipeline = unreal.CustomDemoObjectPipeline()
        return pipeline.execute_pipeline_from_python(file_paths, destination_path)
    
    @staticmethod
    def configure(config_options):
        """é…ç½®ç®¡é“è®¾ç½®"""
        pipeline = unreal.CustomDemoObjectPipeline()
        # å°†Pythonå­—å…¸è½¬æ¢ä¸ºUnreal TMap
        config_map = unreal.Map(str, str)
        for key, value in config_options.items():
            config_map.add(key, str(value))
        pipeline.configure_pipeline_from_python(config_map)
        return pipeline
```

## 4. ä½¿ç”¨ç¤ºä¾‹

### 4.1 åŸºæœ¬å¯¼å…¥ç¤ºä¾‹

```python
import unreal
from custom_interchange import CustomFooTranslator

def import_custom_foo_file(file_path, destination_path="/Game/ImportedAssets/"):
    """å¯¼å…¥è‡ªå®šä¹‰.fooæ ¼å¼æ–‡ä»¶"""
    # æ£€æŸ¥æ–‡ä»¶æ˜¯å¦å­˜åœ¨
    import os
    if not os.path.exists(file_path):
        print(f"File not found: {file_path}")
        return False
    
    # ä½¿ç”¨è‡ªå®šä¹‰ç¿»è¯‘å™¨å¯¼å…¥
    result = CustomFooTranslator.translate_file(file_path, destination_path)
    
    if result:
        print(f"Successfully imported: {file_path}")
        return True
    else:
        print(f"Failed to import: {file_path}")
        return False

# ä½¿ç”¨ç¤ºä¾‹
success = import_custom_foo_file("C:/Assets/MyCustomFile.foo", "/Game/CustomAssets/")
```

### 4.2 é«˜çº§é…ç½®ç¤ºä¾‹

```python
import unreal
from custom_interchange import CustomDemoObjectPipeline

def import_with_custom_settings(file_paths, destination_path, settings=None):
    """ä½¿ç”¨è‡ªå®šä¹‰è®¾ç½®å¯¼å…¥èµ„äº§"""
    # é»˜è®¤è®¾ç½®
    default_settings = {
        "bImportDemoObjects": "true",
        "bAssetSettingBoolean": "false",
        "AssetSettingFloat": "1.5"
    }
    
    # åˆå¹¶ç”¨æˆ·è®¾ç½®
    if settings:
        default_settings.update(settings)
    
    # é…ç½®ç®¡é“
    pipeline = CustomDemoObjectPipeline.configure(default_settings)
    
    # æ‰§è¡Œå¯¼å…¥
    result = CustomDemoObjectPipeline.execute(file_paths, destination_path)
    
    return result

# ä½¿ç”¨ç¤ºä¾‹
files = ["C:/Assets/File1.foo", "C:/Assets/File2.foo"]
custom_settings = {
    "bAssetSettingBoolean": "true",
    "AssetSettingFloat": "2.5"
}

success = import_with_custom_settings(files, "/Game/CustomAssets/", custom_settings)
```

## 5. å®ç°è·¯çº¿å›¾

### 5.1 é˜¶æ®µä¸€ï¼šåŸºç¡€APIæš´éœ²
1. ä¸ºå…³é”®ç±»æ·»åŠ `UFUNCTION`å’Œ`UPROPERTY`æ ‡è®°
2. å®ç°Pythonå‹å¥½çš„åŒ…è£…æ–¹æ³•
3. æ·»åŠ åŸºæœ¬çš„é”™è¯¯å¤„ç†å’Œæ—¥å¿—è®°å½•

### 5.2 é˜¶æ®µäºŒï¼šPythonæ¨¡å—å¼€å‘
1. åˆ›å»ºPythonåŒ…è£…å±‚ç»“æ„
2. å®ç°æ ¸å¿ƒåŠŸèƒ½åŒ…è£…ç±»
3. æ·»åŠ è¾…åŠ©å·¥å…·å’Œå®ç”¨å‡½æ•°

### 5.3 é˜¶æ®µä¸‰ï¼šé«˜çº§åŠŸèƒ½å’Œé›†æˆ
1. å®ç°æ‰¹é‡å¤„ç†å’Œè‡ªåŠ¨åŒ–å·¥å…·
2. æ·»åŠ ä¸å…¶ä»–Pythonæ¨¡å—çš„é›†æˆ
3. å¼€å‘ç¤ºä¾‹è„šæœ¬å’Œæ–‡æ¡£

## 6. ç»“è®º

## 7. é«˜çº§Pythoné›†æˆåº”ç”¨

### 7.1 è‡ªåŠ¨åŒ–å·¥ä½œæµç¨‹é›†æˆ

```python
# custom_interchange/automation.py
import unreal
import os
import json
from pathlib import Path
from typing import List, Dict, Optional
from .translators import CustomFooTranslator
from .pipelines import CustomDemoObjectPipeline

class InterchangeAutomationManager:
    """Interchangeè‡ªåŠ¨åŒ–ç®¡ç†å™¨"""

    def __init__(self):
        self.config_file = "interchange_automation_config.json"
        self.load_configuration()

    def load_configuration(self):
        """åŠ è½½è‡ªåŠ¨åŒ–é…ç½®"""
        if os.path.exists(self.config_file):
            with open(self.config_file, 'r') as f:
                self.config = json.load(f)
        else:
            self.config = self.get_default_config()
            self.save_configuration()

    def save_configuration(self):
        """ä¿å­˜è‡ªåŠ¨åŒ–é…ç½®"""
        with open(self.config_file, 'w') as f:
            json.dump(self.config, f, indent=2)

    def get_default_config(self) -> Dict:
        """è·å–é»˜è®¤é…ç½®"""
        return {
            "watch_folders": [],
            "import_rules": {
                "characters": {
                    "destination": "/Game/Characters/",
                    "pipeline_settings": {
                        "bImportDemoObjects": True,
                        "bAssetSettingBoolean": False,
                        "AssetSettingFloat": 1.0
                    }
                },
                "environments": {
                    "destination": "/Game/Environments/",
                    "pipeline_settings": {
                        "bImportDemoObjects": True,
                        "bAssetSettingBoolean": True,
                        "AssetSettingFloat": 2.0
                    }
                }
            },
            "quality_checks": {
                "enabled": True,
                "max_file_size_mb": 100,
                "allowed_extensions": [".foo", ".bar"]
            }
        }

    def add_watch_folder(self, folder_path: str, category: str):
        """æ·»åŠ ç›‘æ§æ–‡ä»¶å¤¹"""
        watch_entry = {
            "path": folder_path,
            "category": category,
            "enabled": True
        }

        if watch_entry not in self.config["watch_folders"]:
            self.config["watch_folders"].append(watch_entry)
            self.save_configuration()

    def process_folder(self, folder_path: str, category: str) -> Dict:
        """å¤„ç†æ–‡ä»¶å¤¹ä¸­çš„æ‰€æœ‰æ–‡ä»¶"""
        results = {
            "processed": 0,
            "succeeded": 0,
            "failed": 0,
            "details": []
        }

        # è·å–åˆ†ç±»è§„åˆ™
        if category not in self.config["import_rules"]:
            print(f"Unknown category: {category}")
            return results

        rule = self.config["import_rules"][category]
        destination = rule["destination"]
        pipeline_settings = rule["pipeline_settings"]

        # æ‰«ææ–‡ä»¶
        files = self.scan_files(folder_path)
        results["processed"] = len(files)

        # æ‰¹é‡å¤„ç†
        for file_path in files:
            try:
                success = self.process_single_file(file_path, destination, pipeline_settings)
                if success:
                    results["succeeded"] += 1
                    results["details"].append({"file": file_path, "status": "success"})
                else:
                    results["failed"] += 1
                    results["details"].append({"file": file_path, "status": "failed"})
            except Exception as e:
                results["failed"] += 1
                results["details"].append({"file": file_path, "status": "error", "message": str(e)})

        return results

    def scan_files(self, folder_path: str) -> List[str]:
        """æ‰«ææ–‡ä»¶å¤¹ä¸­çš„æœ‰æ•ˆæ–‡ä»¶"""
        valid_files = []
        allowed_extensions = self.config["quality_checks"]["allowed_extensions"]
        max_size_mb = self.config["quality_checks"]["max_file_size_mb"]

        for root, dirs, files in os.walk(folder_path):
            for file in files:
                file_path = os.path.join(root, file)

                # æ£€æŸ¥æ‰©å±•å
                if any(file.lower().endswith(ext) for ext in allowed_extensions):
                    # æ£€æŸ¥æ–‡ä»¶å¤§å°
                    file_size_mb = os.path.getsize(file_path) / (1024 * 1024)
                    if file_size_mb <= max_size_mb:
                        valid_files.append(file_path)
                    else:
                        print(f"File too large: {file_path} ({file_size_mb:.2f}MB)")

        return valid_files

    def process_single_file(self, file_path: str, destination: str, settings: Dict) -> bool:
        """å¤„ç†å•ä¸ªæ–‡ä»¶"""
        # è´¨é‡æ£€æŸ¥
        if not self.perform_quality_check(file_path):
            return False

        # é…ç½®ç®¡é“
        pipeline = CustomDemoObjectPipeline.configure(settings)

        # æ‰§è¡Œå¯¼å…¥
        return CustomFooTranslator.translate_file(file_path, destination)

    def perform_quality_check(self, file_path: str) -> bool:
        """æ‰§è¡Œè´¨é‡æ£€æŸ¥"""
        if not self.config["quality_checks"]["enabled"]:
            return True

        # æ–‡ä»¶å­˜åœ¨æ€§æ£€æŸ¥
        if not os.path.exists(file_path):
            print(f"File not found: {file_path}")
            return False

        # æ–‡ä»¶å¤§å°æ£€æŸ¥
        file_size_mb = os.path.getsize(file_path) / (1024 * 1024)
        max_size = self.config["quality_checks"]["max_file_size_mb"]
        if file_size_mb > max_size:
            print(f"File too large: {file_path} ({file_size_mb:.2f}MB > {max_size}MB)")
            return False

        # æ–‡ä»¶æ ¼å¼æ£€æŸ¥
        allowed_extensions = self.config["quality_checks"]["allowed_extensions"]
        if not any(file_path.lower().endswith(ext) for ext in allowed_extensions):
            print(f"Unsupported file format: {file_path}")
            return False

        return True
```

### 7.2 å®æ—¶ç›‘æ§ç³»ç»Ÿ

```python
# custom_interchange/monitoring.py
import time
import threading
from watchdog.observers import Observer
from watchdog.events import FileSystemEventHandler
from .automation import InterchangeAutomationManager

class InterchangeFileHandler(FileSystemEventHandler):
    """æ–‡ä»¶ç³»ç»Ÿäº‹ä»¶å¤„ç†å™¨"""

    def __init__(self, automation_manager: InterchangeAutomationManager, category: str):
        self.automation_manager = automation_manager
        self.category = category
        self.processing_queue = []
        self.processing_lock = threading.Lock()

    def on_created(self, event):
        """æ–‡ä»¶åˆ›å»ºäº‹ä»¶"""
        if not event.is_directory:
            self.queue_file_for_processing(event.src_path)

    def on_modified(self, event):
        """æ–‡ä»¶ä¿®æ”¹äº‹ä»¶"""
        if not event.is_directory:
            self.queue_file_for_processing(event.src_path)

    def queue_file_for_processing(self, file_path: str):
        """å°†æ–‡ä»¶åŠ å…¥å¤„ç†é˜Ÿåˆ—"""
        with self.processing_lock:
            if file_path not in self.processing_queue:
                self.processing_queue.append(file_path)
                print(f"Queued for processing: {file_path}")

                # å¯åŠ¨å¤„ç†çº¿ç¨‹
                threading.Thread(target=self.process_queued_files, daemon=True).start()

    def process_queued_files(self):
        """å¤„ç†é˜Ÿåˆ—ä¸­çš„æ–‡ä»¶"""
        time.sleep(2)  # ç­‰å¾…æ–‡ä»¶å†™å…¥å®Œæˆ

        with self.processing_lock:
            files_to_process = self.processing_queue.copy()
            self.processing_queue.clear()

        for file_path in files_to_process:
            try:
                # è·å–å¯¼å…¥è§„åˆ™
                if self.category in self.automation_manager.config["import_rules"]:
                    rule = self.automation_manager.config["import_rules"][self.category]
                    success = self.automation_manager.process_single_file(
                        file_path,
                        rule["destination"],
                        rule["pipeline_settings"]
                    )

                    if success:
                        print(f"âœ… Successfully processed: {file_path}")
                    else:
                        print(f"âŒ Failed to process: {file_path}")
                else:
                    print(f"âš ï¸ No rules for category: {self.category}")

            except Exception as e:
                print(f"âŒ Error processing {file_path}: {e}")

class InterchangeMonitoringService:
    """Interchangeç›‘æ§æœåŠ¡"""

    def __init__(self):
        self.automation_manager = InterchangeAutomationManager()
        self.observers = {}
        self.is_running = False

    def start_monitoring(self):
        """å¼€å§‹ç›‘æ§"""
        if self.is_running:
            print("Monitoring is already running")
            return

        watch_folders = self.automation_manager.config["watch_folders"]

        for watch_entry in watch_folders:
            if watch_entry["enabled"]:
                self.add_watch_folder(
                    watch_entry["path"],
                    watch_entry["category"]
                )

        self.is_running = True
        print(f"Started monitoring {len(self.observers)} folders")

    def stop_monitoring(self):
        """åœæ­¢ç›‘æ§"""
        for observer in self.observers.values():
            observer.stop()
            observer.join()

        self.observers.clear()
        self.is_running = False
        print("Stopped monitoring")

    def add_watch_folder(self, folder_path: str, category: str):
        """æ·»åŠ ç›‘æ§æ–‡ä»¶å¤¹"""
        if not os.path.exists(folder_path):
            print(f"Watch folder does not exist: {folder_path}")
            return

        handler = InterchangeFileHandler(self.automation_manager, category)
        observer = Observer()
        observer.schedule(handler, folder_path, recursive=True)
        observer.start()

        self.observers[folder_path] = observer
        print(f"Added watch folder: {folder_path} (category: {category})")

    def remove_watch_folder(self, folder_path: str):
        """ç§»é™¤ç›‘æ§æ–‡ä»¶å¤¹"""
        if folder_path in self.observers:
            self.observers[folder_path].stop()
            self.observers[folder_path].join()
            del self.observers[folder_path]
            print(f"Removed watch folder: {folder_path}")
```

### 7.3 æ‰¹é‡å¤„ç†å’ŒæŠ¥å‘Šç³»ç»Ÿ

```python
# custom_interchange/batch_processor.py
import concurrent.futures
import time
from datetime import datetime
from typing import List, Dict, Callable
from .automation import InterchangeAutomationManager

class BatchProcessor:
    """æ‰¹é‡å¤„ç†å™¨"""

    def __init__(self, max_workers: int = 4):
        self.max_workers = max_workers
        self.automation_manager = InterchangeAutomationManager()
        self.progress_callback: Optional[Callable] = None

    def set_progress_callback(self, callback: Callable[[int, int, str], None]):
        """è®¾ç½®è¿›åº¦å›è°ƒå‡½æ•°"""
        self.progress_callback = callback

    def process_files_parallel(self, file_list: List[str], category: str) -> Dict:
        """å¹¶è¡Œå¤„ç†æ–‡ä»¶åˆ—è¡¨"""
        start_time = time.time()
        results = {
            "total_files": len(file_list),
            "processed": 0,
            "succeeded": 0,
            "failed": 0,
            "start_time": datetime.now().isoformat(),
            "details": []
        }

        # è·å–å¤„ç†è§„åˆ™
        if category not in self.automation_manager.config["import_rules"]:
            results["error"] = f"Unknown category: {category}"
            return results

        rule = self.automation_manager.config["import_rules"][category]

        # å¹¶è¡Œå¤„ç†
        with concurrent.futures.ThreadPoolExecutor(max_workers=self.max_workers) as executor:
            # æäº¤æ‰€æœ‰ä»»åŠ¡
            future_to_file = {
                executor.submit(
                    self.automation_manager.process_single_file,
                    file_path,
                    rule["destination"],
                    rule["pipeline_settings"]
                ): file_path for file_path in file_list
            }

            # å¤„ç†å®Œæˆçš„ä»»åŠ¡
            for future in concurrent.futures.as_completed(future_to_file):
                file_path = future_to_file[future]
                results["processed"] += 1

                try:
                    success = future.result()
                    if success:
                        results["succeeded"] += 1
                        results["details"].append({
                            "file": file_path,
                            "status": "success",
                            "timestamp": datetime.now().isoformat()
                        })
                    else:
                        results["failed"] += 1
                        results["details"].append({
                            "file": file_path,
                            "status": "failed",
                            "timestamp": datetime.now().isoformat()
                        })

                except Exception as e:
                    results["failed"] += 1
                    results["details"].append({
                        "file": file_path,
                        "status": "error",
                        "error": str(e),
                        "timestamp": datetime.now().isoformat()
                    })

                # æ›´æ–°è¿›åº¦
                if self.progress_callback:
                    self.progress_callback(
                        results["processed"],
                        results["total_files"],
                        file_path
                    )

        # å®Œæˆç»Ÿè®¡
        end_time = time.time()
        results["end_time"] = datetime.now().isoformat()
        results["duration_seconds"] = end_time - start_time
        results["files_per_second"] = results["processed"] / results["duration_seconds"] if results["duration_seconds"] > 0 else 0

        return results

    def generate_report(self, results: Dict, output_file: str = None) -> str:
        """ç”Ÿæˆå¤„ç†æŠ¥å‘Š"""
        report_lines = []
        report_lines.append("=" * 60)
        report_lines.append("INTERCHANGE BATCH PROCESSING REPORT")
        report_lines.append("=" * 60)
        report_lines.append(f"Start Time: {results['start_time']}")
        report_lines.append(f"End Time: {results['end_time']}")
        report_lines.append(f"Duration: {results['duration_seconds']:.2f} seconds")
        report_lines.append(f"Processing Speed: {results['files_per_second']:.2f} files/second")
        report_lines.append("")

        # ç»Ÿè®¡ä¿¡æ¯
        report_lines.append("SUMMARY:")
        report_lines.append(f"Total Files: {results['total_files']}")
        report_lines.append(f"Processed: {results['processed']}")
        report_lines.append(f"Succeeded: {results['succeeded']}")
        report_lines.append(f"Failed: {results['failed']}")

        if results['total_files'] > 0:
            success_rate = (results['succeeded'] / results['total_files']) * 100
            report_lines.append(f"Success Rate: {success_rate:.1f}%")

        report_lines.append("")

        # å¤±è´¥è¯¦æƒ…
        failed_files = [detail for detail in results['details'] if detail['status'] != 'success']
        if failed_files:
            report_lines.append("FAILED FILES:")
            for detail in failed_files:
                report_lines.append(f"  âŒ {detail['file']}")
                if 'error' in detail:
                    report_lines.append(f"     Error: {detail['error']}")
            report_lines.append("")

        # æˆåŠŸæ–‡ä»¶ï¼ˆå¯é€‰ï¼Œå¦‚æœæ•°é‡ä¸å¤šï¼‰
        successful_files = [detail for detail in results['details'] if detail['status'] == 'success']
        if successful_files and len(successful_files) <= 20:  # åªæ˜¾ç¤ºå‰20ä¸ªæˆåŠŸæ–‡ä»¶
            report_lines.append("SUCCESSFUL FILES:")
            for detail in successful_files:
                report_lines.append(f"  âœ… {detail['file']}")
            report_lines.append("")

        report_lines.append("=" * 60)

        report_text = "\n".join(report_lines)

        # è¾“å‡ºåˆ°æ§åˆ¶å°
        print(report_text)

        # ä¿å­˜åˆ°æ–‡ä»¶
        if output_file:
            with open(output_file, 'w', encoding='utf-8') as f:
                f.write(report_text)
            print(f"\nReport saved to: {output_file}")

        return report_text
```

## 8. å®Œæ•´ä½¿ç”¨ç¤ºä¾‹

### 8.1 è‡ªåŠ¨åŒ–å·¥ä½œæµç¨‹ç¤ºä¾‹

```python
# example_automation_workflow.py
import os
from custom_interchange.automation import InterchangeAutomationManager
from custom_interchange.monitoring import InterchangeMonitoringService
from custom_interchange.batch_processor import BatchProcessor

def setup_game_asset_automation():
    """è®¾ç½®æ¸¸æˆèµ„äº§è‡ªåŠ¨åŒ–å·¥ä½œæµç¨‹"""

    # åˆ›å»ºè‡ªåŠ¨åŒ–ç®¡ç†å™¨
    automation_manager = InterchangeAutomationManager()

    # é…ç½®ç›‘æ§æ–‡ä»¶å¤¹
    automation_manager.add_watch_folder("D:/GameAssets/Characters/", "characters")
    automation_manager.add_watch_folder("D:/GameAssets/Environments/", "environments")

    # å¯åŠ¨ç›‘æ§æœåŠ¡
    monitoring_service = InterchangeMonitoringService()
    monitoring_service.start_monitoring()

    print("ğŸš€ Game asset automation is now running!")
    print("ğŸ“ Monitoring folders:")
    for watch_entry in automation_manager.config["watch_folders"]:
        print(f"   - {watch_entry['path']} ({watch_entry['category']})")

    return monitoring_service

def batch_import_existing_assets():
    """æ‰¹é‡å¯¼å…¥ç°æœ‰èµ„äº§"""

    # åˆ›å»ºæ‰¹é‡å¤„ç†å™¨
    batch_processor = BatchProcessor(max_workers=6)

    # è®¾ç½®è¿›åº¦å›è°ƒ
    def progress_callback(processed, total, current_file):
        progress = (processed / total) * 100
        print(f"Progress: {progress:.1f}% ({processed}/{total}) - {os.path.basename(current_file)}")

    batch_processor.set_progress_callback(progress_callback)

    # æ”¶é›†è¦å¤„ç†çš„æ–‡ä»¶
    character_files = []
    for root, dirs, files in os.walk("D:/GameAssets/Characters/"):
        for file in files:
            if file.endswith('.foo'):
                character_files.append(os.path.join(root, file))

    print(f"Found {len(character_files)} character files to process")

    # æ‰¹é‡å¤„ç†
    results = batch_processor.process_files_parallel(character_files, "characters")

    # ç”ŸæˆæŠ¥å‘Š
    report_file = f"batch_import_report_{datetime.now().strftime('%Y%m%d_%H%M%S')}.txt"
    batch_processor.generate_report(results, report_file)

    return results

def main():
    """ä¸»å‡½æ•°"""
    print("ğŸ® Starting Interchange Automation System")

    try:
        # 1. æ‰¹é‡å¤„ç†ç°æœ‰æ–‡ä»¶
        print("\nğŸ“¦ Processing existing assets...")
        batch_results = batch_import_existing_assets()

        # 2. å¯åŠ¨å®æ—¶ç›‘æ§
        print("\nğŸ‘ï¸ Starting real-time monitoring...")
        monitoring_service = setup_game_asset_automation()

        # 3. ä¿æŒè¿è¡Œ
        print("\nâœ… System is running. Press Ctrl+C to stop.")
        try:
            while True:
                time.sleep(1)
        except KeyboardInterrupt:
            print("\nğŸ›‘ Stopping automation system...")
            monitoring_service.stop_monitoring()
            print("âœ… System stopped successfully.")

    except Exception as e:
        print(f"âŒ Error: {e}")
        return False

    return True

if __name__ == "__main__":
    import time
    from datetime import datetime
    success = main()
    exit(0 if success else 1)
```

## 9. æ€»ç»“

å°†è‡ªå®šä¹‰Interchangeæ’ä»¶APIæš´éœ²ç»™Pythonæ˜¯å®Œå…¨å¯è¡Œçš„ï¼Œå¹¶ä¸”å¯ä»¥æ˜¾è‘—å¢å¼ºæ’ä»¶çš„åŠŸèƒ½å’Œçµæ´»æ€§ã€‚é€šè¿‡é€‚å½“çš„C++ä¿®æ”¹å’ŒPythonåŒ…è£…å±‚ï¼Œå¯ä»¥å®ç°ä»Pythonè„šæœ¬ä¸­å®Œå…¨æ§åˆ¶è‡ªå®šä¹‰å¯¼å…¥æµç¨‹ï¼Œä¸ºæ¸¸æˆå¼€å‘å›¢é˜Ÿæä¾›å¼ºå¤§çš„è‡ªåŠ¨åŒ–å·¥å…·ã€‚

### ä¸»è¦ä¼˜åŠ¿ï¼š
1. **å®Œå…¨è‡ªåŠ¨åŒ–**: ä»æ–‡ä»¶ç›‘æ§åˆ°èµ„äº§å¯¼å…¥çš„å…¨æµç¨‹è‡ªåŠ¨åŒ–
2. **é«˜åº¦å¯é…ç½®**: é€šè¿‡JSONé…ç½®æ–‡ä»¶çµæ´»è°ƒæ•´å¯¼å…¥è§„åˆ™
3. **å¹¶è¡Œå¤„ç†**: æ”¯æŒå¤šçº¿ç¨‹æ‰¹é‡å¤„ç†ï¼Œæ˜¾è‘—æå‡æ•ˆç‡
4. **å®æ—¶ç›‘æ§**: æ–‡ä»¶ç³»ç»Ÿç›‘æ§ï¼Œå®ç°çƒ­é‡è½½åŠŸèƒ½
5. **è¯¦ç»†æŠ¥å‘Š**: å®Œæ•´çš„å¤„ç†æ—¥å¿—å’Œç»Ÿè®¡æŠ¥å‘Š
6. **é”™è¯¯å¤„ç†**: å¥å£®çš„é”™è¯¯å¤„ç†å’Œæ¢å¤æœºåˆ¶
